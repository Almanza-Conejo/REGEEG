function classPerformance = main(featureMatrixData)
    % Inputs:
    %   featureMatrixData - Matrix of features and responses
    %
    % Outputs:
    %   classPerformance - Struct containing performance metrics of classifiers

    % Load the data
    predictors = featureMatrixData(:, 1:end-1); % Assuming the last column is the response
    responses = featureMatrixData(:, end);
    classNames = unique(responses);

    % Perform 30-fold cross-validation
    k = 30;
    nClassifiers = 5;
    cv = cvpartition(responses, 'KFold', k);
    
    % Save performance metrics
    acc = zeros(k, nClassifiers);

    % Train and test the models
    for f = 1:k
        trainIdx = training(cv, f);
        testIdx = test(cv, f);
        XTrain = predictors(trainIdx, :);
        YTrain = responses(trainIdx);
        XTest = predictors(testIdx, :);
        YTest = responses(testIdx);
        n = numel(YTest);

        % Fit classifiers
        trainedModels = fitClassfiers(XTrain, YTrain, classNames);

        % Evaluate classifiers
        for c = 1:nClassifiers
            YPred = predict(trainedModels{c}, XTest);
            acc(f, c) = sum(YPred == YTest) / n;
            % Compute other performance metrics (accuracy, F1 score, etc.)
        end
    end
    
    % Save performance metrics
    classPerformance.accuracy = acc;
    % Save other performance metrics if necessary

    function trainedModels = fitClassfiers(predictors, responses, classNames)
        % Tune Fine-kNN model
        i = 1;
        trainedModels{i} = fitcknn(predictors, responses, ...
            'Distance', 'Euclidean', ...
            'Exponent', [], ...
            'NumNeighbors', 1, ...
            'DistanceWeight', 'Equal', ...
            'Standardize', true, ...
            'ClassNames', classNames);
        
        % Tune Subspace-kNN model
        i = i + 1;
        trainedModels{i} = fitcensemble(predictors, responses, ...
            'Method', 'Subspace', ...
            'NumLearningCycles', 30, ...
            'Learners', 'knn', ...
            'NPredToSample', max(1, min(108, size(predictors, 2) - 1)), ...
            'ClassNames', classNames);
        
        % Tune Cubic-SVM model
        i = i + 1;
        template = templateSVM('KernelFunction', 'polynomial', ...
            'PolynomialOrder', 3, ...
            'KernelScale', 'auto', ...
            'BoxConstraint', 1, ...
            'Standardize', true);
        cubicSVM = fitcecoc(predictors, responses, ...
            'Learners', template, ...
            'Coding', 'onevsone', ...
            'ClassNames', classNames);
        trainedModels{i} = cubicSVM;

        % Tune Fifth-SVM model
        i = i + 1;
        template = templateSVM('KernelFunction', 'polynomial', ...
            'PolynomialOrder', 5, ...
            'KernelScale', 'auto', ...
            'BoxConstraint', 1, ...
            'Standardize', true);
        fifthSVM = fitcecoc(predictors, responses, ...
            'Learners', template, ...
            'Coding', 'onevsone', ...
            'ClassNames', classNames);
        trainedModels{i} = fifthSVM;

        % Tune Medium Gaussian SVM model
        i = i + 1;
        template = templateSVM('KernelFunction', 'gaussian', ...
            'PolynomialOrder', [], ...
            'KernelScale', 15, ...
            'BoxConstraint', 1, ...
            'Standardize', true);
        gaussianSVM = fitcecoc(predictors, responses, ...
            'Learners', template, ...
            'Coding', 'onevsone', ...
            'ClassNames', classNames);
        trainedModels{i} = gaussianSVM;
    end
end
